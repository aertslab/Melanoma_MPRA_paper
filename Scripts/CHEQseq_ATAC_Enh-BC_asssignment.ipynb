{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancer - BC assignment for 500 bp library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /staging/leuven/stg_00002/lcb/lcb_projects/CSE/500bp_ATAC_peak_library/enhancer_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) Python/3.7.4-foss-2018a => Python/3.7.0-foss-2018a\n",
      "  2) SQLite/3.29.0-GCCcore-6.4.0 => SQLite/3.21.0-GCCcore-6.4.0\n",
      "  3) Tcl/8.6.9-GCCcore-6.4.0 => Tcl/8.6.8-GCCcore-6.4.0\n",
      "  4) XZ/5.2.4-GCCcore-6.4.0 => XZ/5.2.3-GCCcore-6.4.0\n",
      "  5) bzip2/1.0.8-GCCcore-6.4.0 => bzip2/1.0.6-GCCcore-6.4.0\n",
      "  6) libreadline/8.0-GCCcore-6.4.0 => libreadline/7.0-GCCcore-6.4.0\n",
      "  7) ncurses/6.1-GCCcore-6.4.0 => ncurses/6.0-GCCcore-6.4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module load FastQC/0.11.8-Java-1.8.0_162\n",
    "module load cutadapt/1.18-foss-2018a-Python-3.7.0\n",
    "module load SeqKit/0.10.2\n",
    "module load fastp/0.20.0-foss-2018a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw=\"/staging/leuven/stg_00002/lcb/ngs_runs/NovaSeq6000_20191213/Demultiplexed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqc ${path_raw}CSE__10dc17__CheqSeq_500_bp_LC_S49_L00*_R*_001.fastq.gz -o 01.fastqc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.clean_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine R1 and extract free BC with cutadapt\n",
    "cat ${path_raw}CSE__10dc17__CheqSeq_500_bp_LC_S49_L00*_R1_001.fastq.gz > 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1.fastq.gz\n",
    "cutadapt -g CGCACTGGTCACGGAG...AGGCTAGGTGGAGGCTCAGTGagctC -m 8 -M 8 -j 10 --discard-untrimmed \\\n",
    "         -o 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1_BC.fastq.gz 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1.fastq.gz\n",
    "rm 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.18 with Python 3.7.0\n",
      "Command line parameters: -g AATTAATTCGGGCCCCGGTCC...GATCGGCGCGCCTGCTCG -m 17 -M 17 -j 10 --discard-untrimmed 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2.fastq.gz\n",
      "Processing reads on 10 cores in single-end mode ...\n",
      "Finished in 273.00 s (2 us/read; 24.27 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:             110,407,162\n",
      "Reads with adapters:               105,602,464 (95.6%)\n",
      "Reads that were too short:           1,037,617 (0.9%)\n",
      "Reads that were too long:            5,466,728 (5.0%)\n",
      "Reads written (passing filters):   103,902,817 (94.1%)\n",
      "\n",
      "Total basepairs processed: 5,409,950,938 bp\n",
      "Total written (filtered):  1,766,347,889 bp (32.6%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: AATTAATTCGGGCCCCGGTCC...GATCGGCGCGCCTGCTCG; Type: linked; Length: 21+18; 5' trimmed: 105602464 times; 3' trimmed: 105602464 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-21 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-18 bp: 1\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t263\t1725111.9\t0\t263\n",
      "4\t192\t431278.0\t0\t192\n",
      "5\t19\t107819.5\t0\t19\n",
      "8\t1\t1684.7\t0\t1\n",
      "9\t2\t421.2\t0\t2\n",
      "10\t7\t105.3\t1\t3 4\n",
      "11\t6\t26.3\t1\t5 1\n",
      "12\t2\t6.6\t1\t2\n",
      "13\t8\t1.6\t1\t5 3\n",
      "14\t30\t0.4\t1\t20 10\n",
      "15\t59\t0.1\t1\t31 28\n",
      "16\t223\t0.0\t1\t118 105\n",
      "17\t627\t0.0\t1\t552 75\n",
      "18\t1392\t0.0\t1\t263 1019 110\n",
      "19\t25135\t0.0\t1\t1529 7009 16597\n",
      "20\t808416\t0.0\t2\t259219 487795 61402\n",
      "21\t104437736\t0.0\t2\t99906323 3942281 589132\n",
      "22\t231077\t0.0\t2\t15882 178896 36299\n",
      "23\t97012\t0.0\t2\t75 30 96907\n",
      "24\t73\t0.0\t2\t39 22 12\n",
      "25\t54\t0.0\t2\t43 7 4\n",
      "26\t37\t0.0\t2\t26 7 4\n",
      "27\t30\t0.0\t2\t23 3 4\n",
      "28\t29\t0.0\t2\t26 2 1\n",
      "29\t31\t0.0\t2\t26 5\n",
      "32\t1\t0.0\t2\t0 0 1\n",
      "33\t2\t0.0\t2\t1 0 1\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t8516\t1725111.9\t0\t8516\n",
      "4\t14441\t431278.0\t0\t14441\n",
      "5\t7145\t107819.5\t0\t7145\n",
      "6\t6049\t26954.9\t0\t6049\n",
      "7\t10320\t6738.7\t0\t10320\n",
      "8\t17625\t1684.7\t0\t17625\n",
      "9\t28216\t421.2\t0\t27630 586\n",
      "10\t507451\t105.3\t1\t483371 24080\n",
      "11\t103508984\t26.3\t1\t100518022 2990962\n",
      "12\t1338182\t6.6\t1\t1111248 226934\n",
      "13\t63307\t1.6\t1\t55365 7942\n",
      "14\t19908\t0.4\t1\t17382 2526\n",
      "15\t14715\t0.1\t1\t13407 1308\n",
      "16\t9877\t0.0\t1\t6875 3002\n",
      "17\t9094\t0.0\t1\t7401 1693\n",
      "18\t6319\t0.0\t1\t5856 463\n",
      "19\t2492\t0.0\t1\t1666 826\n",
      "20\t4756\t0.0\t1\t2496 2260\n",
      "21\t4528\t0.0\t1\t2501 2027\n",
      "22\t5179\t0.0\t1\t3343 1836\n",
      "23\t4293\t0.0\t1\t2052 2241\n",
      "24\t3381\t0.0\t1\t2747 634\n",
      "25\t2484\t0.0\t1\t1225 1259\n",
      "26\t1814\t0.0\t1\t251 1563\n",
      "27\t1352\t0.0\t1\t775 577\n",
      "28\t1359\t0.0\t1\t947 412\n",
      "29\t250\t0.0\t1\t245 5\n",
      "30\t426\t0.0\t1\t420 6\n",
      "31\t1\t0.0\t1\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine R2 and extract plasmid BC with cutadapt then do rev comp\n",
    "cat ${path_raw}CSE__10dc17__CheqSeq_500_bp_LC_S49_L00*_R2_001.fastq.gz > 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2.fastq.gz\n",
    "cutadapt -g AATTAATTCGGGCCCCGGTCC...GATCGGCGCGCCTGCTCG -m 17 -M 17 -j 10 --discard-untrimmed \\\n",
    "         02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2.fastq.gz |\\\n",
    "seqkit seq -r -p -o 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2_BC.fastq.gz\n",
    "rm 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 107062265\n",
      "total bases: 856498120\n",
      "Q20 bases: 842534947(98.3697%)\n",
      "Q30 bases: 810959428(94.6832%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 104655282\n",
      "total bases: 837242256\n",
      "Q20 bases: 828559842(98.963%)\n",
      "Q30 bases: 801375395(95.7161%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 104655282\n",
      "reads failed due to low quality: 2406983\n",
      "reads failed due to too many N: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 0%\n",
      "\n",
      "JSON report: /dev/null/fastp.json\n",
      "HTML report: /dev/null/fastp.html\n",
      "\n",
      "fastp -e 30 --disable_length_filtering -h /dev/null/fastp.html -j /dev/null/fastp.json -w 8 -o 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1_BCq30.fastq.gz -i 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1_BC.fastq.gz \n",
      "fastp v0.20.0, time used: 185 seconds\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 103902817\n",
      "total bases: 1766347889\n",
      "Q20 bases: 1733937263(98.1651%)\n",
      "Q30 bases: 1674160698(94.7809%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 101385043\n",
      "total bases: 1723501419\n",
      "Q20 bases: 1704564976(98.9013%)\n",
      "Q30 bases: 1652607221(95.8866%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 101385043\n",
      "reads failed due to low quality: 2514192\n",
      "reads failed due to too many N: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 0%\n",
      "\n",
      "JSON report: /dev/null/fastp.json\n",
      "HTML report: /dev/null/fastp.html\n",
      "\n",
      "fastp -e 30 --disable_length_filtering -h /dev/null/fastp.html -j /dev/null/fastp.json -w 8 -o 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2_BCq30.fastq.gz -i 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2_BC.fastq.gz \n",
      "fastp v0.20.0, time used: 291 seconds\n"
     ]
    }
   ],
   "source": [
    "# Q30 filtering\n",
    "for file in 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R*_BC.fastq.gz\n",
    "do\n",
    "fastp -e 30 --disable_length_filtering -h /dev/null/fastp.html -j /dev/null/fastp.json -w 8 \\\n",
    "      -o ${file%_*}_BCq30.fastq.gz \\\n",
    "      -i $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104655282 1217 0.00116287 AAGAATCG 3208727 3.066\n",
      "101391868 1310014 1.29203 ACCTGACACTACAGGTC 19493 0.0192254\n"
     ]
    }
   ],
   "source": [
    "# output one line with total number of reads, number of unique reads, percentage of unique reads, most common sequence, number of occurrence of the most common sequence and frequency of the most common sequence.\n",
    "for file in 02.clean_reads/*_BCq30.fastq.gz\n",
    "do\n",
    "zcat $file | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Enh-freeBC.tsv | while read line\n",
    "do\n",
    "y=$(echo $line | awk '{print $2}')\n",
    "zgrep $y 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R1_BCq30.fastq.gz | wc -l\n",
    "done\n",
    "# ~94% of R1 are known BCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.enhancer_bc_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_NAME=\"CSE__10dc17__CheqSeq_500_bp_LC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutadapt Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@A00311:74:HMLK5DMXX:1:1101:1615:1000 1:N:0:CCAACAAT\n",
      "TTCAGTGG\n",
      "+\n",
      "FFFFFFFF\n",
      "@A00311:74:HMLK5DMXX:1:1101:1850:1000 1:N:0:CCAACAAT\n",
      "TTACGTCC\n",
      "+\n",
      "FFFFFFFF\n",
      "@A00311:74:HMLK5DMXX:1:1101:2193:1000 1:N:0:CCAACAAT\n",
      "ATATCACG\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "zcat 02.clean_reads/${SAMPLE_NAME}_R1_BCq30.fastq.gz|head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the barcode reads,\n",
    "# Create table with following content:\n",
    "# Read ID<TAB>Enhancer Barcode\n",
    "paste \\\n",
    "   <( zcat 02.clean_reads/${SAMPLE_NAME}_R1_BCq30.fastq.gz | sed -n '1~4p' | awk '{print $1}' | sed 's/^@//' ) \\\n",
    "   <( zcat 02.clean_reads/${SAMPLE_NAME}_R1_BCq30.fastq.gz | sed -n '2~4p' ) \\\n",
    "   | sort -k1 \\\n",
    "   | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the barcode reads,\n",
    "# Create table with following content:\n",
    "# Read ID<TAB>Barcode\n",
    "paste \\\n",
    "   <( zcat 02.clean_reads/${SAMPLE_NAME}_R2_BCq30.fastq.gz | sed -n '1~4p' | awk '{print $1}' | sed 's/^@//' ) \\\n",
    "   <( zcat 02.clean_reads/${SAMPLE_NAME}_R2_BCq30.fastq.gz | sed -n '2~4p' ) \\\n",
    "   | sort -k1 \\\n",
    "   | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_barcode.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_barcode.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_barcode.tsv.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_barcode.tsv.gz | sort -k2 | cut -f2 | uniq | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table with following content:\n",
    "# Read ID<TAB>Enhancer Barcode<TAB>Barcode\n",
    "awk -F '\\t' -v OFS='\\t' 'FNR==NR{a[$1]=$2 FS $3;next}{ print $0, a[$1]}' \\\n",
    "   <( zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode.tsv.gz ) \\\n",
    "   <( zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_barcode.tsv.gz ) \\\n",
    "   | awk  '$3!=\"\"' \\\n",
    "   | cut -f1-3 \\\n",
    "   | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode_barcode_coupled.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode_barcode_coupled.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Enh-freeBC.tsv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace enhancer barcode by the enhancer\n",
    "# Create table with following content:\n",
    "# Enhancer<TAB>Barcode\n",
    "awk -F '\\t' -v OFS='\\t' 'FNR==NR{a[$2]=$1; next}{ print a[$2], $3}' \\\n",
    "   <( cat Enh-freeBC.tsv ) \\\n",
    "   <( zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_readID_enhancerBarcode_barcode_coupled.tsv.gz ) \\\n",
    "   | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat Enh-freeBC.tsv | awk '{print $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled.tsv.gz \\\n",
    "   | awk -F'\\t' '$1!=\"\"' \\\n",
    "   | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned.tsv.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only unique couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned.tsv.gz \\\n",
    "   | sort -k1 \\\n",
    "   | uniq \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique.tsv.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique.tsv.gz|head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove barcodes linked to multiple enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique.tsv.gz \\\n",
    "   | awk -F'\\t' '\n",
    "   {\n",
    "      if(a[$2]) {\n",
    "         a[$2]=a[$2]\":\"$1; \n",
    "      } else {\n",
    "         a[$2]=$1;\n",
    "      }\n",
    "   } END {\n",
    "      for (i in a) {\n",
    "         n=split(a[i],b,\":\")\n",
    "         if(n == 1)\n",
    "            print a[i], i;\n",
    "      }\n",
    "   }' OFS='\\t' | gzip -c \\\n",
    "   > 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique_1to1.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03.enhancer_bc_assignment/_enhancer_barcode_coupled_cleaned_unique_1to1.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "echo 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique_1to1.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: 03.enhancer_bc_assignment/_enhancer_barcode_coupled_cleaned_unique_1to1.tsv.gz: No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "zcat 03.enhancer_bc_assignment/${SAMPLE_NAME}_enhancer_barcode_coupled_cleaned_unique_1to1.tsv.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.sequencing_saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DNA sequences from fastq\n",
    "zcat 02.clean_reads/CSE__10dc17__CheqSeq_500_bp_LC_R2_BCq30.fastq.gz | sed -n '2~4p' > 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_BCq30.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘03.sequencing_saturation/parallel.txt’: No such file or directory\n",
      "rm: cannot remove ‘04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_sat.txt’: No such file or directory\n",
      "Academic tradition requires you to cite works you base your article on.\n",
      "When using programs that use GNU Parallel to process data for publication\n",
      "please cite:\n",
      "\n",
      "  O. Tange (2011): GNU Parallel - The Command-Line Power Tool,\n",
      "  ;login: The USENIX Magazine, February 2011:42-47.\n",
      "\n",
      "This helps funding further development; AND IT WON'T COST YOU A CENT.\n",
      "If you pay 10000 EUR you should feel free to use GNU Parallel without citing.\n",
      "\n",
      "To silence the citation notice: run 'parallel --bibtex'.\n",
      "\n",
      "10155\n"
     ]
    }
   ],
   "source": [
    "# Subsample, count total and unique reads\n",
    "start=`date +%s`\n",
    "\n",
    "nreads=$(cat 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_BCq30.txt | wc -l)\n",
    " # Start by removing parallel instructions file\n",
    "rm 03.sequencing_saturation/parallel.txt\n",
    " # Remove any previoulsy created sat values for that file\n",
    "rm 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_sat.txt\n",
    "    for i in $(seq 0 200000 $nreads)\n",
    "    do\n",
    "     # Print number of total and unique reads for every subsamples\n",
    "    echo \"echo $i \\$(shuf -n $(($i)) 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_BCq30.txt | sort | uniq | wc -l) >> 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_sat.txt\" \\\n",
    "    >> 04.sequencing_saturation/parallel.txt\n",
    "    done\n",
    "cat 04.sequencing_saturation/parallel.txt | parallel -j 16\n",
    " # Put values in numerical order\n",
    "cat 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_sat.txt | sort -g > 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_satsort.txt && mv 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_satsort.txt 04.sequencing_saturation/CSE__10dc17__CheqSeq_500_bp_LC_R2_sat.txt\n",
    "\n",
    "end=`date +%s`\n",
    "echo $((end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash 4.2.46",
   "language": "bash",
   "name": "bash4246"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
